% !TeX root = ../main.tex
\section*{Abstract}
\label{ch:abstract}
In recent years, the automotive industry was heavily shaped by the desire to increasingly automate driving tasks. This trend is motivated by statistical findings which indicate that the majority of traffic fatalities are caused by human error \cite{world2018global}. In order to do so, the vehicle obtains motion and occupancy information provided by a diverse set of sensors like cameras, lidars, radars or ultrasonic sensors via a transformation called \gls{ism}. Much research has been done on handcrafted \gls{ism}s to capture more and more sensor characteristics. However, even though the behavior of handcrafted models can be easily tested and, therefore, well understood, they exhibit severe limitations. Some of the biggest challenges are modeling all sensor effects in arbitrary environments for the different types of sensors, the overhead of re-calibrating the \gls{ism}s with occurring changes (e.g. repositioning or updated hardware) and modeling the spatial coherence of detections (e.g. do two detections belong to the same object?). An alternative to handcrafted \gls{ism}s is to learn the sensor characteristics from data. With the improvements of deep learning within the last two decades, end-to-end learned transformations produced competitive or even improved upon their handcrafted counterparts. Nevertheless, the inner workings of models learned from data in an end-to-end manner are currently not well understood. Therefore, these learned \gls{ism}s are mostly treated as black box models which are difficult to test for arbitrary environments.
\\\\
The aim of this work is to thoroughly investigate the current state of learned \gls{ism}s and compare them against handcrafted ones for sensors commonly deployed in automated vehicles. Additionally, methods are investigated to combine the handcrafted with the learned \gls{ism}s predictions to obtain the best of the two worlds. Thus, the contributions are twofold. In the first part baseline handcrafted \gls{ism}s are defined, an architecture search is performed to identify the best learnable model, given imposed restrictions. Also, methods are compared to make the learned models aware of uncertainties, different input encodings for each sensor modality are compared and, eventually, the performance of the leaned \gls{ism}s are compared against each other and the handcrafted ones. In the second part of this work, the temporal accumulation of \gls{ism}s is investigated. Here, problems are identified and solutions are proposed when accumulating predictions from learned \gls{ism}s. Additionally, methods are investigated to combine the predictions of the two types of models. Here, under the assumption that handcrafted \gls{ism}s are better tested then learned ones, a combination is proposed to restrict the influence of learned \gls{ism}s to solely initialize the environment and rely on the handcrafted \gls{ism} for convergence. To this extent, new combination rules are proposed and the results are compared against baseline fusion. All experiments are conducted on the NuScenes dataset \cite{caesar2020nuscenes} which provides real-world urban data from multiple cities.
%
\section*{Kurzfassung}