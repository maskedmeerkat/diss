% !TeX root = ../main.tex
\section*{Abstract}
\label{ch:abstract}
In recent years, the automotive industry was heavily shaped by the desire to increasingly automate driving tasks. This trend is motivated by statistical findings which indicate that the majority of traffic fatalities are caused by human error \cite{world2018global}. In order to automate tasks, the vehicle obtains motion and occupancy information provided by a diverse set of sensors like cameras, lidars, radars or ultrasonic sensors via a transformation called \gls{ism}. Much research has been done on handcrafted \gls{ism}s to capture more and more sensor characteristics. However, even though the behavior of handcrafted models can be easily tested and, therefore, well understood, they exhibit severe limitations. Some of the biggest challenges are modeling all sensor effects in arbitrary environments for the different types of sensors, the overhead of re-calibrating the \gls{ism}s with occurring changes (e.g. repositioning or updated hardware) and modeling the spatial coherence of detections (e.g. "do two detections belong to the same object?"). An alternative to handcrafted \gls{ism}s is to learn the sensor characteristics from data. With the improvements of deep learning within the last two decades, end-to-end learned transformations produce competitive or even improve upon their handcrafted counterparts. Nevertheless, the inner workings of models learned from data in an end-to-end manner are currently not well understood. Therefore, these learned \gls{ism}s are mostly treated as black box models which are difficult to test for arbitrary environments.
\\\\
The aim of this work is to thoroughly investigate the current state of learned \gls{ism}s and compare them against handcrafted ones for sensors commonly deployed in automated vehicles. Additionally, methods are investigated to combine the handcrafted with the learned \gls{ism}s predictions to obtain the best of the two worlds. Thus, the contributions are twofold. In the first part, baseline handcrafted \gls{ism}s are defined and an architecture search is performed to identify the best learnable model, given imposed restrictions. Also, methods are compared to make the learned models aware of uncertainties, different input encodings for each sensor modality are compared and, eventually, the performance of the leaned \gls{ism}s are compared against each other and the handcrafted \gls{ism}s. In the second part of this work, the temporal accumulation of \gls{ism}s is investigated. Here, problems are identified and solutions are proposed when accumulating predictions from learned \gls{ism}s. Additionally, methods are investigated to combine the predictions of the two types of models. Here, under the assumption that handcrafted \gls{ism}s are better tested then the learned ones, a combination is proposed to restrict the influence of learned \gls{ism}s to solely initialize the environment and rely on the handcrafted \gls{ism} for convergence. To this extent, new combination rules are proposed and the results are compared against baseline fusion. All experiments are conducted on the NuScenes dataset \cite{caesar2020nuscenes} which provides real-world urban data from multiple cities.
%
\section*{Kurzfassung}
Ein Trend der letzten Jahre in der Automobilindustrie besteht in der zunehmenden Automatisierung von Fahrtätigkeiten. Dies ist auf Statistiken zurückzuführen, die einen Gro{\ss}teil der Verkehrstode mit menschlichem Fehlverhalten begründet \cite{world2018global}. Um diese Automatisierung zu erreichen, muss dem Fahrzeug Information über die statischen und bewegten Verkehrsteilnehmer bereitgestellt werden. Dies geschieht durch so genannte inverse Sensormodelle (ISMs), die Messungen von Sensoren wie z.B. Kameras, Radaren, Lidaren und Ultraschallsensoren transformieren. Viel Forschung wurde getätigt, um zunehmend mehr Sensorcharakteristiken in händisch definierten \gls{ism}s abzubilden. Diese händischen \gls{ism}s sind aufgrund ihrer Transparenz leicht testbar und somit gut verstanden. Jedoch liegen ihre Schwächen z.B. in der Modellierung aller möglicher Sensoreffekte in generischen Umgebungen, dem Mehraufwand der Rekalibrierung der \gls{ism}s durch Änderungen (z.B. neue Sensorik oder Repositionierung) oder der Modellierung räumlicher Kohärenz von Messungen (z.B. Zuordnung von Detektionen zu Objektinstanzen). Eine Alternative hierzu stellen gelernte \gls{ism}s dar. Diese Modelle haben binnen der letzten zwei Jahrzehnte so stark von den Fortschritten im Bereich Deep Learning profitiert, dass sie die händischen \gls{ism}s eingeholt und, in manchen Fällen, übertroffen haben. Nichtsdestotrotz ist die innere Funktionsweise dieser gelernten Modelle bisher nicht vollständig verstanden. Daher werden sie weitestgehend als Blackbox-Modelle gehandhabt, deren Validierung und Verifikation in generischen Umgebungen noch weiterer Forschung bedarf. Ziel dieser Arbeit ist eine Gegenüberstellung des momentanen Stands gelernter und händisch definierter \gls{ism}s für Sensoren im Automobilbereich. Hinzukommt die Erforschung der Kombination der Prädiktionen beider \gls{ism} Typen mit dem Ziel das Beste aus den Welten zu vereinen. Daher sind die Beiträge der Arbeit zweigeteilt. Im ersten Teil werden Basismodelle für händische \gls{ism}s definiert und die beste Architektur für die gelernten \gls{ism}s unter Berücksichtigung der gegebenen Randbedingungen ermittelt. Weiterhin werden Methoden definiert und gegenübergestellt, um die Messungenauigkeiten in die Prädiktionen der gelernten \gls{ism}s einflie{\ss}en zu lassen. Au{\ss}erdem werden diverse Darstellungen der Messungen für die betrachteten Sensoren gegenübergestellt. Schlie{\ss}lich werden \gls{ism}-Varianten für jeden Sensor gelernt und mit den händischen \gls{ism}s verglichen. Im zweiten Teil wird die zeitliche Akkumulation von \gls{ism}-Prädiktionen betrachtet. In dem Zusammenhang werden auftretende Probleme für gelernte \gls{ism}s identifiziert und Lösungsansätze evaluiert. Des weiteren wird die zeitliche Fusion gelernter und händische \gls{ism}s untersucht. Hierzu wird, unter der Annahme, dass händische \gls{ism}s besser getestet werden können, eine Fusion vorgeschlagen, die die Rolle gelernter \gls{ism}s auf die Initialisierung der Umgebung beschränkt. Dies ermöglicht es den händischen \gls{ism}s das Konvergenzverhalten zu definieren. Alle Experimente werden auf Basis des NuScenes-Datensatzes \cite{caesar2020nuscenes} durchgeführt, welcher reale Messungen aus urbanen Umgebungen mehrerer Städte beinhaltet.